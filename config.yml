Configuration:
  # Set up
  seed: 111  # Set seed
  save_sample_interval: 1   # Save sample every n epochs
  checkpoint_interval: 5  # Save model every n epochs 
  training_mode: alternating  # training mode 'alternating' or 'combined'
  load_checkpoint: False
  training: True
  generate_data: True
  # Visualization
  log_wandb: True
  show_training_process: True
  show_training_evolution: True
  show_sample: False
Hyperparameter:
  num_epochs: 25
  batch_size: 32
  # model selector can have only 1 generator at first index
  model_selector: 'generator,
                  classical_discriminator_1, 
                  classical_discriminator_22, 
                  hybrid_quantum_discriminator_11,'
  models:
    generator:
      learning_rate: 0.0002
      betas: 0.9, 0.999
      model_class: Generator # Select Class for model from models.py
      loss_function: BCELoss  # Any Binary Classification Loss
      optimizer: Adam  # Recommend Adam or RMSprop
    classical_discriminator_1:
      learning_rate: 0.0001
      betas: 0.9, 0.999
      model_class: ClassicalDiscriminator1
      loss_function: BCELoss
      optimizer: Adam
    classical_discriminator_2:
      learning_rate: 0.0001
      betas: 0.9, 0.999
      model_class: ClassicalDiscriminator2
      loss_function: BCELoss
      optimizer: Adam
    hybrid_quantum_discriminator_1:
      learning_rate: 0.0001
      betas: 0.9, 0.999
      model_class: HybridQuantumDiscriminator1
      loss_function: BCELoss
      optimizer: Adam
    quantum_discriminator_1:
      learning_rate: 0.0001
      betas: 0.9, 0.999
      model_class: QuantumDiscriminator1
      loss_function: NLLLoss
      optimizer: Adam